<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Laura WavLM TSE</title>
    <link href="bootstrap-5.3.3-dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="style.css" rel="stylesheet">
  </head>

  <body>
    <div class="container">
      <br>
      <div class="d-flex justify-content-center align-items-center text-center">
        <h1><b>LauraTSE: Target Speaker Extraction using Auto-Regressive
            Decoder-Only Language Models</b></h1>
      </div>
<!--       <div class="d-flex justify-content-center align-items-center text-center">
        <a href="https://beilong-tang.github.io/">Beilong Tang</a>, Bang Zeng,
        Ming Li
      </div> -->
      <br>
      <!-- Paper and Code line -->
      <div class="d-flex justify-content-center align-items-center text-center">
<!--         <div>
          <a href="https://arxiv.org/abs/2504.07402" class="no-link-style me-3">
            <button type="button" class="btn btn-dark pr-4">
              <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"
                fill="currentColor" class="bi bi-file-pdf"
                viewBox="0 0 500 500">
                <path fill="currentColor"
                  d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z">
                </path>
              </svg>
              Paper
            </button>
          </a>
        </div> -->
        <div>
          <a href="https://anonymous.4open.science/r/lauraTSE_code-14AA"
            class="no-link-style">
            <button type="button" class="btn btn-dark">
              <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"
                fill="currentColor" class="bi bi-github"
                viewBox="0 0 16 16">
                <path
                  d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8">
                </path>
              </svg>
              Code
            </button>
          </a>
        </div>
      </div>

      <div class="markdown-body">
        <h2>Abstract</h2>
        <p style="text-align: justify;">
          We propose LauraTSE, an Auto-Regressive Decoder-Only Language Model for Target Speaker Extraction (TSE) based on the LauraGPT backbone. 
          It employs a small-scale auto-regressive decoder-only language model which takes the continuous representations of both the mixture and 
          the reference speech and produces the first few layers of the target speech's discrete codec representations. In addition, a one-step 
          encoder-only language model reconstructs the sum of the predicted codec embeddings using both the mixture and the target speaker's 
          reference information. Our approach achieves superior or comparable performance to existing discriminative TSE models. 
          Moreover, we also study the data scalability and the role of the one-step encoder-only language model in the ablation studies.
        </p>
        <h2>Architecture</h2>
        <div style="width: 100%" class="text-center">
          <img src="assets/model.svg" style="width: 60%;">
          <p>Model Overview of LauraTSE.</p>
        </div>
        <!-- <p style="text-align: justify;">
          Fig 1. shows the our model architecture for TSE task where the input
          is reference speech and mixture speech, and the output is the token
          lists of reference speech and mixture speech. We take the mixture
          output and feed it to Vocoder to output clean speech. For SE, the
          input is noisy and the output is clean speech.
        </p> -->

        <!-- <h2>Model Details</h2>
        <p style="text-align: justify;">
          <li>This model has around 50M parameters with 6 layers of Transformers
            using <a
              href="https://github.com/modelscope/FunCodec">LauraGPT</a>.</li>
          <li>For TSE task, the mixture is first concatenated with the reference
            before passing the WavLM. Is uses the WavLM's capabilites in
            identifying the primary speakers.</li>
          <li>The current vocoder is a Conformer + HifiGan.</li>
          <li>Models are trained on 30 epochs of Libri2Mix.</li>
        </p>
      </div> -->

        <div class="markdown-body">
          <h2> Demo on Libri2Mix Clean</h2>
          <table style="width: 100%;" id="libri2mix_mix_clean">
            <thead>
              <tr>
                <th scope="col">Mixture</th>
                <th scope="col">Ground Truth</th>
                <th scope="col" style="color: red;">LauraTSE</th>
                <th scope="col">Reference</th>
              </tr>
            </thead>
            <tbody>
              <!-- This part will be loaded using script.js -->
            </tbody>
          </table>
        </div>

        <!-- <div class="markdown-body">
          <h2> Comparison between TSELM-L and Spex+</h2>
          <table style="width: 100%;" id="libri2mix_mix_clean_compare">
            <thead>
              <tr>
                <th scope="col">Mixture</th>

                <th scope="col" style="color: red;">LauraTSE</th>
                <th scope="col">TSELM-L</th>
                <th scope="col">Spex+</th>
                <th scope="col">Ground Truth</th>
                <th scope="col">Reference</th>
              </tr>
            </thead>
            <tbody>

            </tbody>
          </table>
        </div>

      </div> -->

        <script src="bootstrap-5.3.3-dist/js/bootstrap.bundle.min.js"></script>
        <script src="script.js"></script>
      </body>

    </html>
